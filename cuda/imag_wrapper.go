package cuda

/*
 THIS FILE IS AUTO-GENERATED BY CUDA2GO.
 EDITING IS FUTILE.
*/

import (
	"github.com/mumax/3/cuda/cu"
	"github.com/mumax/3/timer"
	"sync"
	"unsafe"
)

// CUDA handle for imag kernel
var imag_code cu.Function

// Stores the arguments for imag kernel invocation
type imag_args_t struct {
	arg_output unsafe.Pointer
	arg_input  unsafe.Pointer
	arg_N      int
	argptr     [3]unsafe.Pointer
	sync.Mutex
}

// Stores the arguments for imag kernel invocation
var imag_args imag_args_t

func init() {
	// CUDA driver kernel call wants pointers to arguments, set them up once.
	imag_args.argptr[0] = unsafe.Pointer(&imag_args.arg_output)
	imag_args.argptr[1] = unsafe.Pointer(&imag_args.arg_input)
	imag_args.argptr[2] = unsafe.Pointer(&imag_args.arg_N)
}

// Wrapper for imag CUDA kernel, asynchronous.
func k_imag_async(output unsafe.Pointer, input unsafe.Pointer, N int, cfg *config) {
	if Synchronous { // debug
		Sync()
		timer.Start("imag")
	}

	imag_args.Lock()
	defer imag_args.Unlock()

	if imag_code == 0 {
		imag_code = fatbinLoad(imag_map, "imag")
	}

	imag_args.arg_output = output
	imag_args.arg_input = input
	imag_args.arg_N = N

	args := imag_args.argptr[:]
	cu.LaunchKernel(imag_code, cfg.Grid.X, cfg.Grid.Y, cfg.Grid.Z, cfg.Block.X, cfg.Block.Y, cfg.Block.Z, 0, stream0, args)

	if Synchronous { // debug
		Sync()
		timer.Stop("imag")
	}
}

// maps compute capability on PTX code for imag kernel.
var imag_map = map[int]string{0: "",
	50: imag_ptx_50,
	52: imag_ptx_52,
	53: imag_ptx_53,
	60: imag_ptx_60,
	61: imag_ptx_61,
	62: imag_ptx_62,
	70: imag_ptx_70,
	72: imag_ptx_72,
	75: imag_ptx_75,
	80: imag_ptx_80}

// imag PTX code for various compute capabilities.
const (
	imag_ptx_50 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_50
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
	imag_ptx_52 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_52
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
	imag_ptx_53 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_53
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
	imag_ptx_60 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_60
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
	imag_ptx_61 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_61
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
	imag_ptx_62 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_62
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
	imag_ptx_70 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_70
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
	imag_ptx_72 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_72
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
	imag_ptx_75 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_75
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
	imag_ptx_80 = `
<<<<<<< HEAD
.version 8.5
=======
.version 8.4
>>>>>>> origin/region_solver
.target sm_80
.address_size 64

	// .globl	imag

.visible .entry imag(
	.param .u64 imag_param_0,
	.param .u64 imag_param_1,
	.param .u32 imag_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<10>;
	.reg .b64 	%rd<9>;


	ld.param.u64 	%rd1, [imag_param_0];
	ld.param.u64 	%rd2, [imag_param_1];
	ld.param.u32 	%r2, [imag_param_2];
	mov.u32 	%r3, %ctaid.y;
	mov.u32 	%r4, %nctaid.x;
	mov.u32 	%r5, %ctaid.x;
	mad.lo.s32 	%r6, %r3, %r4, %r5;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	setp.ge.s32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd3, %rd2;
	shl.b32 	%r9, %r1, 1;
	mul.wide.s32 	%rd4, %r9, 4;
	add.s64 	%rd5, %rd3, %rd4;
	ld.global.nc.f32 	%f1, [%rd5+4];
	cvta.to.global.u64 	%rd6, %rd1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.f32 	[%rd8], %f1;

$L__BB0_2:
	ret;

}

`
)
